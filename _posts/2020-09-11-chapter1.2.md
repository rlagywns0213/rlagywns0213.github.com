---
title:  "[Chapter1] 핸즈온 머신러닝 with Scikit-Learn, Keras & TensorFlow을 읽고 - 2"
header:
  teaser: "/assets/images/book.jpeg"

excerpt: "핸즈온 머신러닝 책을 통하여 사이킷런, 케라스, 텐서플로2를 활용한 머신러닝, 딥러닝 완벽 실무를 익히고자 한다."
categories:
  - Data Analysis
tags:
  - Python
  - TensorFlow
  - Keras
  - machine learning
last_modified_at: 2020-09-11T16:01:04-04:00
toc: true
toc_label: "On this page"

---
### 4\. 머신러닝 시스템의 종류
***
#### 4.1.1 지도 학습

**지도 학습**은 알고리즘에 주입하는 훈련 데이터에 **레이블**이라는 원하는 답이 포함된다.

- 분류 : 전형적인 지도 학습 작업  (ex). 스팸 필터
- 회귀 : 예측 변수라 부르는 특성을 사용해 타깃(target) 수치를 예측하는 것
- k-최근접 이웃
- 선형 회귀
- 로지스틱 회귀
- 서포트 벡터 머신
- 결정 트리와 랜덤 포레스트
- 신경망

#### 4.1.2 비지도 학습

**비지도 학습**은 말 그대로 훈련 데이터에 레이블이 없고, 시스템이 아무런 도움 없이 학습한다.

1. 군집
  - k-평균
  - DBSCAN
  - 계층 군집 분석
  - 이상치 탐지와 특이치 탐지
  - 원-클래스
  - 아이솔레이션 포레스트
2. 시각화와 차원 축소
  - 주성분 분석
  - 커널 PCA
  - 지역적 선형 임베딩
  - t-SNE
3. 연관 규칙 학습
  - 어프라이어리
  - 이클렛

#### 4.1.3 준지도 학습

데이터에 레이블을 다는 것은 시간, 비용 많이 들기 때문에 레이블이 없는 샘플이 많고, 레이블된 샘플은 적은 경우가 많다.<br>
-> 일부만 레이블이 있는 데이터를 다루는 **준지도 학습** <br>
(지도 학습과 비지도 학습의 조합)  
ex) 구글 포토 호스팅 서비스

#### 4.1.4 강화 학습

**강화 학습**은 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습한다.<br>
ex) 알파고


#### 4.2 배치 학습과 온라인 학습
머신러닝 시스템을 분류하는데 사용하는 다른 기준은 입력 데이터의 스트림부터 점진적으로 학습할 수 있는지 여부이다.

##### -  배치 학습

  먼저, 시스템을 훈련시키고 제품 시스템에 적용하면 더 이상의 학습 없이 실행된다. <br>
  **즉, 학습한 것을 단지 적용만 하는 오프라인 학습이다.**
  구체적으로 새로운 데이터에 대해 학습하려면, <br>
  1. 전체 데이터를 사용하여  시스템의 새로운 버전을 처음부터 다시 훈련
  2. 그 후, 이전 시스템 중지시키고 새 시스템으로 교체


    - 시스템이 점진적으로 학습할 수 없다.
    - 가용한 데이터를 모두 사용해 훈련시켜야 하므로 시간과 자원을 많이 소모한다.
    - 시스템이 빠르게 변화하는 데이터(ex.주식가격)에 적응하려면 더 능동적인 방법 필요하다.
    - 전체 데이터셋을 사용해 훈련한다면 많은 컴퓨팅 자원이 필요하다. (큰 비용 발생)

      **--> 점진적으로 학습할 수 있는 알고리즘을 사용하는 편이 낫다.**

##### - 온라인 학습

  데이터를 순차적으로 한 개씩 또는 **_미니배치_**라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다.<br>
  **즉, 점진적 학습(incremental learning)이다.**

    - 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습 가능하다.
    - 빠른 변화에 스스로 적응하는 시스템에 적합
    - 컴퓨팅 자원이 제한된 경우에도 유용
    - 온라인 학습 시스템이 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더는 필요하지 않으므로 버리면 된다. (많은 공간 절약**)
    - 컴퓨터 한대의 메인 메모리에 들어갈 수 없는 큰 데이터셋 학습하는 시스템에 사용 가능 (일명. 외부 메모리 학습)

- 중요한 파라미터 : **학습률(learning late)**<br>
    학습률을 높이면, 시스템이 데이터에 빠르게 적응하지만 예전 데이터 금방 잊어버릴 것임 <br>
    학습률이 낮으면, 시스템의 관성이 더 커져 더 느리게 학습하지만 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐.

- 문제점 : 시스템에 나쁜 데이터 주입되면, 시스템 성능이 **점진적으로 감소한다.**<br>
    _ex) 검색 엔진을 속여 검색 결과 상위에 노출시키려는 누군가로부터의 나쁜 데이터_

    -> 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학습을 중지시켜야 한다. <br>
    -> 혹은, 입력 데이터를 모니터링해서 비정상 데이터를 잡아낸다. (이상치 탐지 알고리즘)

#### 4.3 사례 기반 학습과 모델 기반 학습

머신러닝 목표 : **일반화** --> 새로운 샘플에 잘 작동하는 모델

##### -  사례 기반 학습

- 스팸 메일과 동일한 메일을 스팸이라고 지정한다.
- 두 메일 사이의 유사도를 측정하여 유사한 메일을 구분하도록 프로그래밍한다.
- 즉, 스팸 메일과 곹옹으로 가지고 있는 단어가 많으면 스팸으로 분류!!

##### -  모델 기반 학습

: 샘플로부터 일반화시키는 다른 방법은 샘플들의 모델을 만들어 예측에 사용하는 것!

EX) OECD, IMF 데이터 표

|국가|1인당 GDP|삶의 만족도|
|------|---|---|
|헝가리|12,240|4.9|
|대한민국|27,195|5.8|
|프랑스|37,675|6.5|
|호주|50,962|7.3|
|미국|55,805|7.2|

- 모델 선택 : 1인당 GDP의 선형 함수로 삶의 만족도를 모델링
- 선형 모델 : 1인당 GDP라는 특성 하나를 가진 삶의 만족도에 대한 선형 모델
- 모델 파라미터 : 모델이 최상의 성능을 내도록 하는 파라미터값을 찾아야 한다.

 > 모델이 얼마나 좋은지 측정하는 **효용 함수** 를 정의하거나 <br>
 얼마나 나쁜지 측정하는 **비용 함수**를 정의한다.

선형 회귀 : 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용 함수 사용, **_이 거리를 최소화하는 것_**이 목표!!

- 예제 1-1 사이킷런을 이용한 선형 모델의 훈련과 실행

예제의 데이터는 이전 글의 깃허브 주소에서 다운받을 수 있다.

```Python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn.linear_model

#데이터 적재
oecd_bli = pd.read_csv("oecd_bli_2015.csv", thousands=',')
gdp_per_capita = pd.read_csv("gdp_per_capita.csv", thousands=',', delimiter='\t', encoding = 'latin1', na_values="n/a")

def prepare_country_stats(oecd_bli, gdp_per_capita):
    oecd_bli = oecd_bli[oecd_bli["INEQUALITY"]=="TOT"]
    oecd_bli = oecd_bli.pivot(index="Country", columns="Indicator", values="Value")
    gdp_per_capita.rename(columns={"2015": "GDP per capita"}, inplace=True)
    gdp_per_capita.set_index("Country", inplace=True)
    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,
                                  left_index=True, right_index=True)
    full_country_stats.sort_values(by="GDP per capita", inplace=True)
    remove_indices = [0, 1, 6, 8, 33, 34, 35]
    keep_indices = list(set(range(36)) - set(remove_indices))
    return full_country_stats[["GDP per capita", 'Life satisfaction']].iloc[keep_indices]
```
>위의 함수는 OECD의 삶의 만족도(life satisfaction) 데이터와 IMF의 1인당 GDP(GDP per capita) 데이터를 합치는 함수이다.<br>

결과는 다음과 같다.

```Python
#데이터 준비
country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)
country_stats
```
![capture](https://user-images.githubusercontent.com/28617444/92768104-a8dda080-f3d2-11ea-87bd-f26afeb9d9c6.PNG)

다음으로, 선형 모델을 만들어 주기 위해 numpy 의 np.c_ 를 통해 두 개의 1차원 배열을 칼럼으로 세로로 붙여서 2차원 배열로 만든다.

이를 시각화 하면 다음과 같다.

```Python
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]

#데이터 시각화
country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction')
plt.show()
```
![capture](https://user-images.githubusercontent.com/28617444/92768596-1b4e8080-f3d3-11ea-9373-c9a294cb31db.PNG)

이제 사이킷런 라이브러리의 선형모델을 불러와 훈련시킨다.

```Python
#선형 모델 선택
model = sklearn.linear_model.LinearRegression()

#모델 훈련
model.fit(X,y)

#키프로스에 대한 예측 만들기
X_new = [[22587]]
print(model.predict(X_new))
```

이 모델을 통해, **OECD 데이터에 없는** 키프로스 사람들이 얼마나 행복한지를 파악할 수 있다. <br> 모델을 통한 예측값은 5.96 이다.
- 요약
  1. 데이터를 분석
  2. 모델 선택
  3. 훈련 데이터로 모델 훈련(학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터 찾음)
  4. 새로운 데이터에 모델을 적용해 예측


### 5\. 머신러닝의 주요 도전 과제
***
### 6\. 테스트와 검증
***
### 7\. 연습문제
***
