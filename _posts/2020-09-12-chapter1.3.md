---
title:  "[Chapter1] 핸즈온 머신러닝 with Scikit-Learn, Keras & TensorFlow을 읽고 - 3"
header:
  teaser: "/assets/images/book.jpeg"

excerpt: "핸즈온 머신러닝 책을 통하여 사이킷런, 케라스, 텐서플로2를 활용한 머신러닝, 딥러닝 완벽 실무를 익히고자 한다."
categories:
  - 핸즈온 머신러닝
tags:
  - Python
  - TensorFlow
  - Keras
  - machine learning
last_modified_at: 2020-09-11T16:01:04-04:00
toc: true
toc_ads: true
toc_label: "On this page"

---
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Frlagywns0213.github.io%2F%25ED%2595%25B8%25EC%25A6%2588%25EC%2598%25A8%2520%25EB%25A8%25B8%25EC%258B%25A0%25EB%259F%25AC%25EB%258B%259D%2Fchapter1.3%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=%EC%A1%B0%ED%9A%8C%EC%88%98&edge_flat=false)](https://hits.seeyoufarm.com)
### 5\. 머신러닝의 주요 도전 과제
***
머신러닝의 두 가지 주요 작업은 **학습 알고리즘**을 선택해서, **어떤 데이터에** 훈련시키는 것다.<br>
따라서, "나쁜 알고리즘", "나쁜 데이터"를 고려해야 할 사안이다.

먼저, 네가지 나쁜 데이터에 대해 살펴보겠다.


**-  충분하지 않은 양의 훈련 데이터**

머신러닝 알고리즘의 성공을 위해서는, 데이터가 많아야 한다.<br>
수천 개의 데이터, 넘어서 복잡한 문제라면 수백만 개가 필요할지도 모른다

**- 대표성 없는 훈련 데이터**

  일반화가 잘되기 위해서는 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다. <br>
따라서, 일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 매우 중요하지만, 이는 매우 어렵다.

  샘플이 작으면 **샘플링 잡음**이 생기고, <br>
  매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못해 **샘플링 편향**이 생긴다.

**- 낮은 품질의 데이터**

  훈련 데이터가 _에러, 이상치, 잡음_ 가득하다면 내재된 패턴 파악 불가<br>
  따라서, **훈련 데이터 정제**에 많은 시간 투자할 가치가 있다.

  + 훈련 데이터 정제가 필요한 경우
  > 일부 샘플이 이상치라는게 명확한 경우,
  >>무시 or 수정<br>

    > 일부 샘플에 특성 몇 개가 빠져 있는 경우,<br>
    >>특성 무시 or 샘플 무시 or 값 대체 <br>
    or 이 특 성을 넣은 모델과 제외한 모델을 따로 훈련시킬지 결정


**- 관련 없는 특성**

  훈련 데이터에 관련 없는 특성이 적고, 관련 있는 특성이 충분해야 학습 가능<br>
  즉, 성공적인 머신러닝 프로젝트의 핵심 요소는 **훈련에 사용할 좋은 특성들을 찾는 것**

  = _특성 공학_

    - 특성 선택 : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택
    - 특성 추출 : 특성을 결합하여 더 유용한 특성을 만듬
    (ex. 차원축소 알고리즘이 도움 됨)
    - 새로운 데이터를 수집해 새 특성을 만든다.


다음으로 두가지 나쁜 알고리즘에 대해 살펴보겠다.


  **- 훈련 데이터 과대적합**

만약, 해외 여행 중 택시운전자가 내 물건을 훔쳤을 때, 그 나라의 모든 택시운전자를 도둑이라고 판단하는 것 <br>
이를, **과대적합(overfitting)** 이라 한다.<br>
즉, 모델이 훈련 데이터에 너무 잘 맞아 일반성이 떨어지는 것<br>
훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다.
- 과대 적합의 해결방법
> 파라미터 수가 적은 모델을 선택, 훈련 데이터에 있는 특성 수 줄임, 모델에 제약을 가하며 단순화시킴 <br>
훈련 데이터를 더 많이 모음 <br>
훈련 데이터의 잡음을 줄임 (오류 데이터 수정 , 이상치 제거 등)

- 규제

 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것
 <br> 데이터에 완벽히 맞추는 것과 일반화를 위해 단순한 모델을 유지하는 것 사이의 올바른 균형을 찾아야 한다!!


 - 하이퍼파라미터(hyperparameter)

 학습하는 동안 적용할 규제의 양을 결정하는 학습 알고리즘의 파라미터<br>
 학습 알고리즘으로부터 영향 받지 않으며 훈련전에 미리 지정되고, 훈련하는 동안 상수로 남아 있다. <br>
 머신러닝 시스템 구축할 때 **하이퍼파라미터 튜닝**은 매우 중요한 과정임!


 **- 훈련 데이터 과대적합**

과대적합의 반댓말<br>
모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생<br>

  - 과소 적합의 해결방법

  >모델 파라미터가 더 많은 강력한 모델을 선택한다.<br>
   학습 알고리즘에 더 좋은 특성을 제공한다. (특성공학)<br>
   모델의 제약을 줄인다. (규제 하이퍼파라미터 감소)

### 6\. 테스트와 검증
***

모델을 학습시켰다 해서 새로운 샘플에 일반화되는 정도가 어느 정도인지, 모델을 평가하고 다시금 상세하게 튜닝하는 작업이 필요하다. <br>
모델이 새로운 샘플에 얼마나 잘 일반화될지 알기 위해서 실제 서비스에 넣고 구현해야 하지만 많은 무리가 있다. <br>

 따라서, 훈련 데이터를 **train set** 과 **test set**으로 나누어서 train set으로 모델을 훈련시키고, test set으로 모델을 테스트한다. <br>

    - 새로운 샘플에 대한 오류 비율 = 일반화 오차(generalization error)라고 하며  
      test set에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻는다.
      -> 이전에 본 적 없는 새로운 샘플에 모델이 얼마나 잘 작동할지 알려준다.

 훈련 오차가 낮지만 일반화 오차가 높다면 이는 모델이 훈련 데이터에 과대적합되었다는 뜻!


  **- 하이퍼파라미터 튜닝과 모델 선택**

만약, 모델 평가 후 선형 모델이 더 잘 일반화되었다고 가정하고, 과대적합 피하기 위해 규제를 적용하려고 한다면, 하이퍼파라미터 값을 어떻게 선택해야 할까?

1. : 100개의 하이퍼 파라미터 값으로 100개의 다른 모델을 훈련시킨다. <BR>

  -> 일반화 오차가 가장 낮은 모델을 만드는 최적의 하이퍼파라미터를 찾았지만, 실제 서비스에 모델 투입 시 성능이 저하되고 오차가 늘어난다. <br>

  *일반화 오차를 테스트 세트에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들었기 때문*

2. 위에 대한 해결방법이 **홀드아웃 검증(holdout validation)**이다.

  간단하게 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택하는 것<br>
  이 새로운 홀드 아웃 세트를 **검증 세트(validation set)**라 한다. <br>

  - 과정

          -  줄어든 훈련 세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련한다.
          그 다음 검증 세트에서 가장 높은 성능을 내는 모델을 선택한다.
          홀드아웃 검증 과정이 끝나면, 이 최선의 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만든다.
          마지막으로 최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정한다.

  - 문제점

    검증 세트가 너무 작으면 -> 모델이 정확하게 평가되지 않음<br>

    검증 세트가 너무 크면 -> 훈련 세트가 전체 훈련 세트보다 너무 작아짐<br>
    -> 최종 모델이 전체 훈련세트에서 훈련되기 때문에 너무 작은 훈련 세트에서 훈련한 후보 모델을 비교하는 것은 이상적이지 않다.

3. 이 문제를 해결하는 방법인 **교차 검증(cross validation)**

  작은 검증 세트를 여러 개를 사용해 반복적인 교차 검증을 수행하는 것이다.<br>
  검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가한다.

  **모든 모델의 평가를 평균**하면 훨씬 정확한 성능 측정 가능!!<br>
  그러나, 훈련 시간이 검증 세트의 개수에 비례해 늘어난다는 단점도 존재



  **- 데이터 불일치**

  어떠한 경우는, 많은 양의 훈련 데이터를 얻는다 해도 데이터가 실제 제품에 사용될 데이터를 완벽하게 대표하지 못할 수도 있다.

-  꽃 사진 분류 모델 ( 수백만개의 꽃 사진)

    이 경우, 검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 잘 대표해야 한다.<br>
    따라서, 검증 세트와 테스트 세트에 대표 사진이 배타적으로 포함되어야 한다.

    이를 위해, 웹에서 다운로드한 수백만개의 훈련 사진의 일부롤 떼어내어 또 다른 세트를 만든다.<br>
    **훈련-개발 세트(train-dev set)** <br>

    >즉, 모델을 훈련 세트에서 훈련한 다음, 훈련-개발 세트에서 평가한다. <br>
    이 모델이 검증 세트에서 나쁜 성능을 낸다면, 데이터 불일치 문제 의심!!<br>
    >>  --> 웹 이미지를 모바일 앱에서 찍은 사진처럼 보이도록 전처리한 다음, 다시 훈련하여 해결

    >반대로, 모델이 훈련-개발 세트에서 잘 작동하지 않는다면, 훈련 세트에 과대적합된 것!!<br>
      >>--> 모델 규제 or 더 많은 훈련 데이터 모으거나 훈련 데이터 정제 시도
